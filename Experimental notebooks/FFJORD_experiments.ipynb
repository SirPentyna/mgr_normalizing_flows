{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with FFJORD\n",
    "https://github.com/rtqichen/ffjord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.datasets import make_circles\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = {\n",
    "    'adjoint':True,\n",
    "    'viz':True,\n",
    "    'niters':1000,\n",
    "    'lr': 1e-3,\n",
    "    'num_samples':512,\n",
    "    'width':64,\n",
    "    'hidden_dim':32,\n",
    "    'gpu':0,\n",
    "    'train_dir':None,\n",
    "    'results_dir':\"./results\"\n",
    "}\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--adjoint', action='store_true')\n",
    "# parser.add_argument('--viz', action='store_true')\n",
    "# parser.add_argument('--niters', type=int, default=1000)\n",
    "# parser.add_argument('--lr', type=float, default=1e-3)\n",
    "# parser.add_argument('--num_samples', type=int, default=512)\n",
    "# parser.add_argument('--width', type=int, default=64)\n",
    "# parser.add_argument('--hidden_dim', type=int, default=32)\n",
    "# parser.add_argument('--gpu', type=int, default=0)\n",
    "# parser.add_argument('--train_dir', type=str, default=None)\n",
    "# parser.add_argument('--results_dir', type=str, default=\"./results\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "if args['adjoint']:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDistribution(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, num_samples):\n",
    "        \"\"\"Sample from distribution and calculate log prob\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def log_prob(self, z):\n",
    "        \"\"\"Calculate log prob for batch\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class NormUnif(MyDistribution):\n",
    "    \"\"\"Mixture with standard normal distribution and uniform distribution on a rectangle\n",
    "    Args:\n",
    "          x_dim: Dimension of each data point\n",
    "          prob_delta: probability of normal distribution\n",
    "          K_intervals: intervals that construct a rectangle - first row is a0, a1, ... and second row b0, b1, ...\n",
    "                        and rectangle is constructed based on (a0, b0), (a1, b1), ...\n",
    "    \"\"\"\n",
    "    def __init__(self, x_dim, prob_delta, K_intervals):\n",
    "        super().__init__()\n",
    "\n",
    "        self.x_dim = x_dim\n",
    "        self.prob_delta = prob_delta\n",
    "        self.K_intervals = K_intervals\n",
    "\n",
    "        self.K_area = torch.prod(torch.diff(self.K_intervals, dim = 0))\n",
    "\n",
    "        self.m = torch.distributions.MultivariateNormal(torch.zeros(self.x_dim), torch.eye(self.x_dim))\n",
    "\n",
    "    def calculate_pdf(self, sample_point):\n",
    "\n",
    "        if len(sample_point.shape) == 1:\n",
    "            is_in_area = torch.sum(\n",
    "                torch.logical_and(\n",
    "                    torch.gt(sample_point, self.K_intervals[0]),\n",
    "                    torch.lt(sample_point, self.K_intervals[1])\n",
    "                    )\n",
    "                )\n",
    "            return self.prob_delta * np.exp(m.log_prob(sample_point)) + (1 - self.prob_delta) * (1 / self.K_area) * is_in_area\n",
    "\n",
    "        elif len(sample_point.shape) == 2:\n",
    "            is_in_area = \\\n",
    "            torch.eq( \n",
    "            torch.sum(torch.logical_and(\n",
    "                torch.gt(sample_point, self.K_intervals[0]),\n",
    "                torch.lt(sample_point, self.K_intervals[1])), dim = 1), \n",
    "            sample_point.shape[1] * torch.ones((sample_point.shape[0],)))\n",
    "\n",
    "            return self.prob_delta * np.exp(self.m.log_prob(sample_point)) + (1 - self.prob_delta) * (1 / self.K_area) * is_in_area\n",
    "\n",
    "    def log_prob(self, z):\n",
    "        return torch.log(self.calculate_pdf(z))\n",
    "\n",
    "    def prob_greater_t(self, t):\n",
    "        # Probability of Normal part\n",
    "        standard_norm =  torch.distributions.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "\n",
    "        prob_norm = (1 - standard_norm.cdf(t))**self.x_dim\n",
    "\n",
    "        # Probability of rectangle part\n",
    "        a = self.K_intervals[0]\n",
    "        b = self.K_intervals[1]\n",
    "        max_at = np.maximum(a, torch.ones(len(a))*t)\n",
    "\n",
    "        int_len = torch.maximum(b- max_at, torch.zeros(len(b)))\n",
    "        area_above_t = torch.prod(int_len)\n",
    "        prob_rectangle = area_above_t / self.K_area\n",
    "\n",
    "        return self.prob_delta * prob_norm + (1 - self.prob_delta) * prob_rectangle\n",
    "\n",
    "\n",
    "    def forward(self, num_samples=1):\n",
    "        # Sample from X\n",
    "        # 1) Sample delta\n",
    "        delta = torch.bernoulli(torch.ones((num_samples, 1))*self.prob_delta)\n",
    "\n",
    "        # 2) Sample from Z\n",
    "        \n",
    "        Z = self.m.sample((num_samples,))\n",
    "\n",
    "        # 3) Sample from K\n",
    "        K = torch.rand(num_samples, self.x_dim)\n",
    "\n",
    "\n",
    "        #1st row\n",
    "        K_start = self.K_intervals[0][None, :] # dimension expanded\n",
    "\n",
    "        # start minus end\n",
    "        K_range = torch.diff(self.K_intervals, dim = 0)\n",
    "\n",
    "        #K times range plus starting points\n",
    "        K = K *  K_range + K_start\n",
    "\n",
    "        # 4) Take X\n",
    "\n",
    "        X = delta * Z   + (1 - delta) * K\n",
    "        return  X, self.log_prob(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(num_samples):\n",
    "    \n",
    "    prob_delta = 0.5\n",
    "    K_intervals = torch.Tensor([[0.5, 1],\n",
    "                            [3,3]])\n",
    "    nu = NormUnif(x_dim = 2, prob_delta=prob_delta, K_intervals=K_intervals)\n",
    "    points= nu.forward(num_samples)[0].numpy()\n",
    "    x = torch.tensor(points).type(torch.float32).to(device)\n",
    "    logp_diff_t1 = torch.zeros(num_samples, 1).type(torch.float32).to(device)\n",
    "\n",
    "    return(x, logp_diff_t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1, running avg loss: 4.4731\n",
      "Iter: 2, running avg loss: 4.4720\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CNF(nn.Module):\n",
    "    \"\"\"Adapted from the NumPy implementation at:\n",
    "    https://gist.github.com/rtqichen/91924063aa4cc95e7ef30b3a5491cc52\n",
    "    \"\"\"\n",
    "    def __init__(self, in_out_dim, hidden_dim, width):\n",
    "        super().__init__()\n",
    "        self.in_out_dim = in_out_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.width = width\n",
    "        self.hyper_net = HyperNetwork(in_out_dim, hidden_dim, width)\n",
    "\n",
    "    def forward(self, t, states):\n",
    "        z = states[0]\n",
    "        logp_z = states[1]\n",
    "\n",
    "        batchsize = z.shape[0]\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            z.requires_grad_(True)\n",
    "\n",
    "            W, B, U = self.hyper_net(t)\n",
    "\n",
    "            Z = torch.unsqueeze(z, 0).repeat(self.width, 1, 1)\n",
    "\n",
    "            h = torch.tanh(torch.matmul(Z, W) + B)\n",
    "            dz_dt = torch.matmul(h, U).mean(0)\n",
    "\n",
    "            dlogp_z_dt = -trace_df_dz(dz_dt, z).view(batchsize, 1)\n",
    "\n",
    "        return (dz_dt, dlogp_z_dt)\n",
    "\n",
    "\n",
    "def trace_df_dz(f, z):\n",
    "    \"\"\"Calculates the trace of the Jacobian df/dz.\n",
    "    Stolen from: https://github.com/rtqichen/ffjord/blob/master/lib/layers/odefunc.py#L13\n",
    "    \"\"\"\n",
    "    sum_diag = 0.\n",
    "    for i in range(z.shape[1]):\n",
    "        sum_diag += torch.autograd.grad(f[:, i].sum(), z, create_graph=True)[0].contiguous()[:, i].contiguous()\n",
    "\n",
    "    return sum_diag.contiguous()\n",
    "\n",
    "\n",
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"Hyper-network allowing f(z(t), t) to change with time.\n",
    "    Adapted from the NumPy implementation at:\n",
    "    https://gist.github.com/rtqichen/91924063aa4cc95e7ef30b3a5491cc52\n",
    "    \"\"\"\n",
    "    def __init__(self, in_out_dim, hidden_dim, width):\n",
    "        super().__init__()\n",
    "\n",
    "        blocksize = width * in_out_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 3 * blocksize + width)\n",
    "\n",
    "        self.in_out_dim = in_out_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.width = width\n",
    "        self.blocksize = blocksize\n",
    "\n",
    "    def forward(self, t):\n",
    "        # predict params\n",
    "        params = t.reshape(1, 1)\n",
    "        params = torch.tanh(self.fc1(params))\n",
    "        params = torch.tanh(self.fc2(params))\n",
    "        params = self.fc3(params)\n",
    "\n",
    "        # restructure\n",
    "        params = params.reshape(-1)\n",
    "        W = params[:self.blocksize].reshape(self.width, self.in_out_dim, 1)\n",
    "\n",
    "        U = params[self.blocksize:2 * self.blocksize].reshape(self.width, 1, self.in_out_dim)\n",
    "\n",
    "        G = params[2 * self.blocksize:3 * self.blocksize].reshape(self.width, 1, self.in_out_dim)\n",
    "        U = U * torch.sigmoid(G)\n",
    "\n",
    "        B = params[3 * self.blocksize:].reshape(self.width, 1, 1)\n",
    "        return [W, B, U]\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "#### Here cam be added my data type\n",
    "def get_batch_their(num_samples):\n",
    "    points, _ = make_circles(n_samples=num_samples, noise=0.06, factor=0.5)\n",
    "    x = torch.tensor(points).type(torch.float32).to(device)\n",
    "    logp_diff_t1 = torch.zeros(num_samples, 1).type(torch.float32).to(device)\n",
    "\n",
    "    return(x, logp_diff_t1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t0 = 0\n",
    "    t1 = 10\n",
    "    device = torch.device('cuda:' + str(args['gpu'])\n",
    "                          if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # model\n",
    "    func = CNF(in_out_dim=2, hidden_dim=args['hidden_dim'], width=args['width']).to(device)\n",
    "    optimizer = optim.Adam(func.parameters(), lr=args['lr'])\n",
    "    p_z0 = torch.distributions.MultivariateNormal(\n",
    "        loc=torch.tensor([0.0, 0.0]).to(device),\n",
    "        covariance_matrix=torch.tensor([[1.0, 0.0], [0.0, 1.0]]).to(device)\n",
    "    )\n",
    "    loss_meter = RunningAverageMeter()\n",
    "\n",
    "    if args['train_dir'] is not None:\n",
    "        if not os.path.exists(args['train_dir']):\n",
    "            os.makedirs(args['train_dir'])\n",
    "        ckpt_path = os.path.join(args['train_dir'], 'ckpt.pth')\n",
    "        if os.path.exists(ckpt_path):\n",
    "            checkpoint = torch.load(ckpt_path)\n",
    "            func.load_state_dict(checkpoint['func_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            print('Loaded ckpt from {}'.format(ckpt_path))\n",
    "\n",
    "    try:\n",
    "        x, logp_diff_t1 = get_batch(args['num_samples'])\n",
    "        for itr in range(1, args['niters'] + 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #x, logp_diff_t1 = get_batch(args['num_samples'])\n",
    "\n",
    "            z_t, logp_diff_t = odeint(\n",
    "                func,\n",
    "                (x, logp_diff_t1),\n",
    "                torch.tensor([t1, t0]).type(torch.float32).to(device),\n",
    "                atol=1e-5,\n",
    "                rtol=1e-5,\n",
    "                method='dopri5',\n",
    "            )\n",
    "\n",
    "            z_t0, logp_diff_t0 = z_t[-1], logp_diff_t[-1]\n",
    "\n",
    "            logp_x = p_z0.log_prob(z_t0).to(device) - logp_diff_t0.view(-1)\n",
    "            loss = -logp_x.mean(0)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_meter.update(loss.item())\n",
    "\n",
    "            print('Iter: {}, running avg loss: {:.4f}'.format(itr, loss_meter.avg))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keybard Interrupted!\")\n",
    "    #     if args.train_dir is not None:\n",
    "    #         ckpt_path = os.path.join(args.train_dir, 'ckpt.pth')\n",
    "    #         torch.save({\n",
    "    #             'func_state_dict': func.state_dict(),\n",
    "    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         }, ckpt_path)\n",
    "    #         print('Stored ckpt at {}'.format(ckpt_path))\n",
    "    print('Training complete after {} iters.'.format(itr))\n",
    "\n",
    "    if args['viz']:\n",
    "        viz_samples = 30000\n",
    "        viz_timesteps = 41\n",
    "        target_sample, _ = get_batch(viz_samples)\n",
    "\n",
    "        if not os.path.exists(args['results_dir']):\n",
    "            os.makedirs(args['results_dir'])\n",
    "        with torch.no_grad():\n",
    "            # Generate evolution of samples\n",
    "            z_t0 = p_z0.sample([viz_samples]).to(device)\n",
    "            logp_diff_t0 = torch.zeros(viz_samples, 1).type(torch.float32).to(device)\n",
    "\n",
    "            z_t_samples, _ = odeint(\n",
    "                func,\n",
    "                (z_t0, logp_diff_t0),\n",
    "                torch.tensor(np.linspace(t0, t1, viz_timesteps)).to(device),\n",
    "                atol=1e-5,\n",
    "                rtol=1e-5,\n",
    "                method='dopri5',\n",
    "            )\n",
    "\n",
    "            # Generate evolution of density\n",
    "            x = np.linspace(-5.0, 5.0, 100)\n",
    "            y = np.linspace(-5.0, 5.0, 100)\n",
    "            points = np.vstack(np.meshgrid(x, y)).reshape([2, -1]).T\n",
    "\n",
    "            z_t1 = torch.tensor(points).type(torch.float32).to(device)\n",
    "            logp_diff_t1 = torch.zeros(z_t1.shape[0], 1).type(torch.float32).to(device)\n",
    "\n",
    "            z_t_density, logp_diff_t = odeint(\n",
    "                func,\n",
    "                (z_t1, logp_diff_t1),\n",
    "                torch.tensor(np.linspace(t1, t0, viz_timesteps)).to(device),\n",
    "                atol=1e-5,\n",
    "                rtol=1e-5,\n",
    "                method='dopri5',\n",
    "            )\n",
    "\n",
    "            # Create plots for each timestep\n",
    "            for (t, z_sample, z_density, logp_diff) in zip(\n",
    "                    np.linspace(t0, t1, viz_timesteps),\n",
    "                    z_t_samples, z_t_density, logp_diff_t\n",
    "            ):\n",
    "                fig = plt.figure(figsize=(12, 4), dpi=200)\n",
    "                plt.tight_layout()\n",
    "                plt.axis('off')\n",
    "                plt.margins(0, 0)\n",
    "                fig.suptitle(f'{t:.2f}s')\n",
    "\n",
    "                ax1 = fig.add_subplot(1, 3, 1)\n",
    "                ax1.set_title('Target')\n",
    "                ax1.get_xaxis().set_ticks([])\n",
    "                ax1.get_yaxis().set_ticks([])\n",
    "                ax2 = fig.add_subplot(1, 3, 2)\n",
    "                ax2.set_title('Samples')\n",
    "                ax2.get_xaxis().set_ticks([])\n",
    "                ax2.get_yaxis().set_ticks([])\n",
    "                ax3 = fig.add_subplot(1, 3, 3)\n",
    "                ax3.set_title('Log Probability')\n",
    "                ax3.get_xaxis().set_ticks([])\n",
    "                ax3.get_yaxis().set_ticks([])\n",
    "\n",
    "                ax1.hist2d(*target_sample.detach().cpu().numpy().T, bins=300, density=True,\n",
    "                           range=[[-5.0, 5.0], [-5.0, 5.0]])\n",
    "\n",
    "                ax2.hist2d(*z_sample.detach().cpu().numpy().T, bins=300, density=True,\n",
    "                           range=[[5.0, 5.0], [-5.0, 5.0]])\n",
    "\n",
    "                logp = p_z0.log_prob(z_density) - logp_diff.view(-1)\n",
    "                ax3.tricontourf(*z_t1.detach().cpu().numpy().T,\n",
    "                                np.exp(logp.detach().cpu().numpy()), 200)\n",
    "\n",
    "                plt.savefig(os.path.join(args['results_dir'], f\"cnf-viz-{int(t*1000):05d}.jpg\"),\n",
    "                           pad_inches=0.2, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            img, *imgs = [Image.open(f) for f in sorted(glob.glob(os.path.join(args['results_dir'], f\"cnf-viz-*.jpg\")))]\n",
    "            img.save(fp=os.path.join(args['results_dir'], \"cnf-viz-4.gif\"), format='GIF', append_images=imgs,\n",
    "                     save_all=True, duration=250, loop=0)\n",
    "\n",
    "        print('Saved visualization animation at {}'.format(os.path.join(args['results_dir'], \"cnf-viz-4.gif\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6819c49ba5a09ca392b5492c0f94828bf52946dc6ae61b12b9bc870288a3edfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
